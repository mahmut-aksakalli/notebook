{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pytorch_Review.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"roSF_iKpzUEd","colab_type":"text"},"source":["## What is PyTorch?\n","It’s a Python-based scientific computing package targeted at two sets of audiences:\n","\n","* A replacement for NumPy to use the power of GPUs\n","* a deep learning research platform that provides maximum flexibility and speed"]},{"cell_type":"markdown","metadata":{"id":"eivjkuwo0qFV","colab_type":"text"},"source":["### Tensors\n","\n","Tensors are similar to NumPy’s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n","\n"]},{"cell_type":"code","metadata":{"id":"Ak1oFMqmzdmN","colab_type":"code","colab":{}},"source":["import torch\n","import numpy as np\n","\n","## different ways to create Tensor\n","x1 = torch.zeros(5,3, dtype=torch.long)\n","x2 = torch.rand(5,3)\n","x3 = torch.Tensor(5,3)\n","x4 = torch.Tensor(5,3).uniform_(-1,1)   ## create 5x3 matrix with values between -1 to 1\n","x5 = torch.Tensor([1, 5 ,7 ,9])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dBBoKKST3E3I","colab_type":"code","outputId":"34ae2a85-96be-4797-a32b-b200d2d93564","executionInfo":{"status":"ok","timestamp":1552897218982,"user_tz":-60,"elapsed":991,"user":{"displayName":"Mahmut Aksakallı","photoUrl":"","userId":"14563906430510929603"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# operations\n","y1 = x2 + x4\n","y2 = torch.add(x2,x4)\n","\n","# add x to y\n","y1.add_(x4)\n","\n","## You can use standard NumPy-like indexing with all bells and whistles!\n","print(y1[:,1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([-0.6745,  0.2601, -0.0147,  1.3664, -0.4267])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JAQKDEng3sn4","colab_type":"text"},"source":["#### Note\n","Any operation that mutates a tensor in-place is post-fixed with an _. For example: x.copy_(y), x.t_(), will change x."]},{"cell_type":"code","metadata":{"id":"c8jMjbME4mnS","colab_type":"code","outputId":"ba080d8f-2b7d-47dd-9143-5449ed589b92","executionInfo":{"status":"ok","timestamp":1552897312163,"user_tz":-60,"elapsed":883,"user":{"displayName":"Mahmut Aksakallı","photoUrl":"","userId":"14563906430510929603"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x = torch.randn(4,4)\n","\n","y = x.view(16)\n","z = x.view(-1,8)  # the size -1 is inferred from other dimensions\n","\n","print(x.size(), y.size(), z.size())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A_bCd29F5j1z","colab_type":"text"},"source":["#### Numpy Bridge\n","The Torch Tensor and NumPy array will share their underlying memory locations, and changing one will change the other."]},{"cell_type":"code","metadata":{"id":"7gzEabym5gxl","colab_type":"code","outputId":"2314afd3-486b-471f-fd48-6ca1cefae46b","executionInfo":{"status":"ok","timestamp":1552897581137,"user_tz":-60,"elapsed":745,"user":{"displayName":"Mahmut Aksakallı","photoUrl":"","userId":"14563906430510929603"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["a = torch.ones(5)\n","b = a.numpy()\n","\n","print(a)\n","print(b)\n","\n","a.add_(1)\n","print(a)\n","print(b)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([1., 1., 1., 1., 1.])\n","[1. 1. 1. 1. 1.]\n","tensor([2., 2., 2., 2., 2.])\n","[2. 2. 2. 2. 2.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bu5EEdYb6J0s","colab_type":"code","outputId":"fb61fbca-4509-4d09-efa6-7da93384225c","executionInfo":{"status":"ok","timestamp":1552897685007,"user_tz":-60,"elapsed":730,"user":{"displayName":"Mahmut Aksakallı","photoUrl":"","userId":"14563906430510929603"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["a1 = np.ones(5)\n","b1 = torch.from_numpy(a1)\n","\n","np.add(a1, 1, out=a1)\n","print(a1)\n","print(b1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[2. 2. 2. 2. 2.]\n","tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9IuNx41V8d-H","colab_type":"text"},"source":["####  Autograd : automatic differentiation\n","The autograd package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different.\n","\n","\n","torch.Tensor is the central class of the package. If you set its attribute .requires_grad as True, it starts to track all operations on it. When you finish your computation you can call .backward() and have all the gradients computed automatically. The gradient for this tensor will be accumulated into .grad attribute."]},{"cell_type":"code","metadata":{"id":"yPsT026b8dFO","colab_type":"code","outputId":"9b3c1164-a708-4d93-ae0d-69699abc4a13","executionInfo":{"status":"ok","timestamp":1586982775295,"user_tz":-180,"elapsed":721,"user":{"displayName":"Mahmut Aksakallı","photoUrl":"","userId":"14563906430510929603"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["x = torch.ones(2,2, requires_grad=True)\n","print(x)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[1., 1.],\n","        [1., 1.]], requires_grad=True)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CuXVV5yL9jCT","colab_type":"code","outputId":"aea7b372-8347-40c1-da89-2d54f4e20646","executionInfo":{"status":"ok","timestamp":1586982820321,"user_tz":-180,"elapsed":711,"user":{"displayName":"Mahmut Aksakallı","photoUrl":"","userId":"14563906430510929603"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["y = x+2\n","z = y*y*3\n","out = z.mean()\n","out"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(27., grad_fn=<MeanBackward0>)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"82JqaB0m9mTq","colab_type":"code","outputId":"80ff2f4e-ce90-4a5e-db8c-de56391ec195","executionInfo":{"status":"ok","timestamp":1552903183360,"user_tz":-60,"elapsed":860,"user":{"displayName":"Mahmut Aksakallı","photoUrl":"","userId":"14563906430510929603"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["out.backward()\n","x.grad"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[13.5000, 13.5000],\n","        [13.5000, 13.5000]])"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"Xi4MPwRdPib6","colab_type":"text"},"source":["### Neural Networks\n","Neural networks can be constructed using the torch.nn package.\n","\n","nn.Module contains layers, and a method forward(input)that returns the output.\n","\n","![alt text](https://pytorch.org/tutorials/_images/mnist.png)\n","\n","A typical training procedure for a neural network is as follows:\n","\n","* Define the neural network that has some learnable parameters (or weights)\n","* Iterate over a dataset of inputs\n","* Process input through the network\n","* Compute the loss (how far is the output from being correct)\n","* Propagate gradients back into the network’s parameters\n","* Update the weights of the network, typically using a simple \n"," update rule: \n"," >* weight = weight - learning_rate \\* gradient"]},{"cell_type":"code","metadata":{"id":"WyV6JVJb9uVK","colab_type":"code","outputId":"f1b790d4-c31a-4db6-9ef3-148a20b29e5c","executionInfo":{"status":"ok","timestamp":1552904684833,"user_tz":-60,"elapsed":792,"user":{"displayName":"Mahmut Aksakallı","photoUrl":"","userId":"14563906430510929603"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Net(nn.Module):\n","  \n","  def __init__(self):\n","    super(Net, self).__init__()\n","    \n","    self.conv1 = nn.Conv2d(1, 6, 5) # 1 input channel, 6 output chan., 5x5 conv kernel\n","    self.conv2 = nn.Conv2d(6, 16, 5)\n","    self.fc1 = nn.Linear(16*5*5, 120)\n","    self.fc2 = nn.Linear(120, 84)\n","    self.fc3 = nn.Linear(84, 10)\n","    \n","  def forward(self, x):\n","    # Max pooling over a (2,2) window or just 2\n","    x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n","    x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n","    x = x.view(-1, self.num_flat_features(x))\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    x = self.fc3(x)\n","    return x\n","  \n","  def num_flat_features(self, x):\n","    size = x.size()[1:] # all dimensions except the bactch dim.\n","    num_features = 1\n","    for s in size:\n","      num_features *= s\n","    return num_features\n","  \n","net = Net()\n","print(net)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Net(\n","  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n","  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","  (fc1): Linear(in_features=400, out_features=120, bias=True)\n","  (fc2): Linear(in_features=120, out_features=84, bias=True)\n","  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Mcu53VhNUKc_","colab_type":"text"},"source":["The learnable parameters of a model are returned by net.parameters()"]},{"cell_type":"code","metadata":{"id":"EcPusOPeUMC4","colab_type":"code","outputId":"e0a2ad0b-a844-48e5-94a5-d790e70b6653","executionInfo":{"status":"ok","timestamp":1552904500108,"user_tz":-60,"elapsed":1565,"user":{"displayName":"Mahmut Aksakallı","photoUrl":"","userId":"14563906430510929603"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["params = list(net.parameters())\n","print(len(params))\n","print(params[0].size())  # conv1's .weight"],"execution_count":0,"outputs":[{"output_type":"stream","text":["10\n","torch.Size([6, 1, 5, 5])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SgyYg7F6UvPv","colab_type":"text"},"source":["Let try a random 32x32 input. "]},{"cell_type":"code","metadata":{"id":"XJ7m7qntUwzJ","colab_type":"code","outputId":"c7ca8c94-484f-4ecf-dce8-8a4e6a5d797f","executionInfo":{"status":"ok","timestamp":1552905239779,"user_tz":-60,"elapsed":852,"user":{"displayName":"Mahmut Aksakallı","photoUrl":"","userId":"14563906430510929603"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["input = torch.randn(1, 1, 32, 32)\n","\n","out = net(input)\n","print(out)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[ 0.0414,  0.0925,  0.0325,  0.0966,  0.0247, -0.0236,  0.0521, -0.0203,\n","         -0.0744, -0.1122]], grad_fn=<AddmmBackward>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mV_PYE6QV6Be","colab_type":"text"},"source":["#### Note \n","torch.nn only supports mini-batches. The entire torch.nn package only supports inputs that are a mini-batch of samples, and not a single sample.\n","\n","For example, nn.Conv2d will take in a 4D Tensor of \n","> nSamples x nChannels x Height x Width.\n","\n","If you have a single sample, just use input.unsqueeze(0) to add a fake batch dimension."]},{"cell_type":"markdown","metadata":{"id":"uoXCUR0hWnzB","colab_type":"text"},"source":["#### Loss Function\n","A loss function takes the (output, target) pair of inputs, and computes a value that estimates how far away the output is from the target."]},{"cell_type":"code","metadata":{"id":"afLNeqdoVL8X","colab_type":"code","outputId":"854fda91-d5c0-48a2-9543-239c8cde2278","executionInfo":{"status":"ok","timestamp":1552906835189,"user_tz":-60,"elapsed":771,"user":{"displayName":"Mahmut Aksakallı","photoUrl":"","userId":"14563906430510929603"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["output = net(input)\n","\n","target = torch.randn(10)    ## a dummy target\n","target = target.view(1, -1) ## make it the same shape as out\n","criterion = nn.MSELoss()    ## computer mean-squared error\n","\n","loss = criterion(output, target)\n","print(loss)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor(0.4255, grad_fn=<MseLossBackward>)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0F-YDHIbYvBW","colab_type":"text"},"source":["Now, if you follow loss in the backward direction, using its .**grad_fn attribute**, you will see a graph of computations that looks like this:\n","\n","* **input** -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n","     >* -> view -> linear -> relu -> linear -> relu -> linear\n","     >* -> MSELoss\n","     >* -> loss"]},{"cell_type":"code","metadata":{"id":"IxxRsKusZnvp","colab_type":"code","outputId":"a77bb97b-2df2-43b8-f4e9-3a04cb453869","executionInfo":{"status":"ok","timestamp":1552906766721,"user_tz":-60,"elapsed":752,"user":{"displayName":"Mahmut Aksakallı","photoUrl":"","userId":"14563906430510929603"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["print(loss.grad_fn)\n","print(loss.grad_fn.next_functions[0][0]) # Linear\n","print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) # ReLU\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<MseLossBackward object at 0x7fdef189ea90>\n","<AddmmBackward object at 0x7fdef189e9b0>\n","<AccumulateGrad object at 0x7fdef189ea90>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"syz4kwQ_cXJx","colab_type":"text"},"source":["To backpropagate the error all we have to do is to loss.backward() You need to clear the existing gradients though, else gradients will be accumulated to existing gradients."]},{"cell_type":"code","metadata":{"id":"ZyW2zT-tchgY","colab_type":"code","outputId":"0577f20b-09c1-4fca-cc23-eedd1f242bd0","executionInfo":{"status":"ok","timestamp":1552906769429,"user_tz":-60,"elapsed":855,"user":{"displayName":"Mahmut Aksakallı","photoUrl":"","userId":"14563906430510929603"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["net.zero_grad() # zeroes the gradient buffers of all params\n","\n","print('conv1.bias.grad before backward')\n","print(net.conv1.bias.grad)\n","\n","loss.backward()\n","\n","print('conv1.bias.grad after backward')\n","print(net.conv1.bias.grad)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["conv1.bias.grad before backward\n","tensor([0., 0., 0., 0., 0., 0.])\n","conv1.bias.grad after backward\n","tensor([-0.0210, -0.0019, -0.0038, -0.0027,  0.0046,  0.0106])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_NReuC6ddku-","colab_type":"text"},"source":["#### Update the weights\n","The simplest update rule used in practice is the Stochastic Gradient Descent (SGD):\n","> weight = weight - learning_rate * gradient"]},{"cell_type":"code","metadata":{"id":"kidGn6Gpdtp7","colab_type":"code","colab":{}},"source":["lr = 0.01\n","for f in net.parameters():\n","  f.data.sub_(f.grad.data * lr)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PQRclgHjeWiG","colab_type":"text"},"source":["**torch.optim** package contains different update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc."]},{"cell_type":"code","metadata":{"id":"zrIWioZVejBi","colab_type":"code","outputId":"e2c5ebc7-3907-4021-e79c-5d76b7695826","executionInfo":{"status":"ok","timestamp":1552911083381,"user_tz":-60,"elapsed":1212,"user":{"displayName":"Mahmut Aksakallı","photoUrl":"","userId":"14563906430510929603"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import torch.optim as optim\n","\n","optimizer = optim.SGD(net.parameters(), lr=0.01) ## create optimizer\n","\n","optimizer.zero_grad() # zero the gradient buffers\n","\n","output = net(input)\n","loss   = criterion(output, target)\n","print('loss:', loss.item())\n","\n","loss.backward()\n","optimizer.step()  # does the update\n","\n","output = net(input)\n","loss   = criterion(output, target)\n","print('loss after one cycle:', loss.item())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["loss: 0.41491034626960754\n","loss after one cycle: 0.4058629870414734\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EjEuL1cBu88T","colab_type":"text"},"source":["### Training a Classifier\n","\n","#### What about data?\n","Generally, when you have to deal with image, text, audio or video data, you can use standard python packages that load data into a numpy array. Then you can convert this array into a torch.*Tensor.\n","\n","* For images, packages such as Pillow, OpenCV are useful\n","* For audio, packages such as scipy and librosa\n","* For text, either raw Python or Cython based loading, or NLTK and SpaCy are useful\n","\n","Specifically for vision, we have created a package called **torchvision**, that has data loaders for common datasets such as Imagenet, CIFAR10, MNIST, etc\n","\n","#### We will do the following steps in order:\n","\n","* Load and normalizing the CIFAR10 training and test datasets using torchvision\n","* Define a Convolutional Neural Network\n","* Define a loss function\n","* Train the network on the training data\n","* Test the network on the test data"]},{"cell_type":"code","metadata":{"id":"MJ_K49Smv2FR","colab_type":"code","colab":{}},"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BwvHE9y_3Oa0","colab_type":"text"},"source":["##### Load and normalizing the CIFAR10 training and test datasets"]},{"cell_type":"code","metadata":{"id":"loDcitsZwGWk","colab_type":"code","outputId":"cc9c9add-b3e8-4124-99a1-c82f7722407e","executionInfo":{"status":"ok","timestamp":1552975805376,"user_tz":-60,"elapsed":2028,"user":{"displayName":"Mahmut Aksakallı","photoUrl":"","userId":"14563906430510929603"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## output of torchvision datasets are PILImage images of range [0, 1]\n","## so transform them to Tensors of normalized range[-1,1]\n","transform = transforms.Compose([transforms.ToTensor(),\n","                               transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n","                                        download=True, transform=transform)\n","\n","## data loader\n","train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=64,\n","                                           shuffle=True, num_workers=2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RWK-vmIGxECk","colab_type":"code","outputId":"d2d86864-7104-4c71-8657-3d6d47c95926","executionInfo":{"status":"ok","timestamp":1552975809084,"user_tz":-60,"elapsed":806,"user":{"displayName":"Mahmut Aksakallı","photoUrl":"","userId":"14563906430510929603"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["## fetch one data pair\n","image, label = trainset[0]\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","print(image.size())\n","print('label: ',classes[label])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([3, 32, 32])\n","label:  frog\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GCurx7cd05VK","colab_type":"code","outputId":"ed6b40fd-0a18-4ac8-ef9e-bde0598f6f30","executionInfo":{"status":"ok","timestamp":1552977013370,"user_tz":-60,"elapsed":744,"user":{"displayName":"Mahmut Aksakallı","photoUrl":"","userId":"14563906430510929603"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# get some random training images\n","dataiter = iter(train_loader)\n","images, labels = dataiter.next()\n","\n","[classes[i] for i in labels[:10]]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['deer',\n"," 'car',\n"," 'horse',\n"," 'deer',\n"," 'truck',\n"," 'frog',\n"," 'ship',\n"," 'frog',\n"," 'deer',\n"," 'bird']"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"q3r_mhBI3XES","colab_type":"text"},"source":["##### Define a Convolutional Neural Network"]},{"cell_type":"code","metadata":{"id":"8G0nGKrY2Kr_","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 16 * 5 * 5)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","\n","net = Net()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yHpah5W_3iJ5","colab_type":"text"},"source":["##### Define a loss function"]},{"cell_type":"code","metadata":{"id":"OpE_nMRQ3mF0","colab_type":"code","colab":{}},"source":["import torch.optim as optim\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2wjIVezj3wuQ","colab_type":"text"},"source":["##### Train the network on the training data"]},{"cell_type":"code","metadata":{"id":"bgi00QxB31l_","colab_type":"code","outputId":"29464a3d-6f8a-4603-f72c-34b5f203ebbc","executionInfo":{"status":"ok","timestamp":1552977142261,"user_tz":-60,"elapsed":47589,"user":{"displayName":"Mahmut Aksakallı","photoUrl":"","userId":"14563906430510929603"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["for epoch in range(2):    ## loop over the dataset multiple times\n","  \n","  running_loss = 0.0\n","  for i,data in enumerate(train_loader, 0):\n","    \n","    inputs, labels = data\n","    \n","    optimizer.zero_grad()  ## zero the params gradients\n","    \n","    ## forward + backward + optimize\n","    output = net(inputs)\n","    loss = criterion(output, labels)\n","    loss.backward()\n","    optimizer.step()\n","    \n","    running_loss += loss.item()\n","    if i%200 == 199:\n","      print('[%d, %5d] loss:%.3f' % (epoch+1, i+1, running_loss/2000))\n","      running_loss=0\n","\n","print('Finished Training')      "],"execution_count":0,"outputs":[{"output_type":"stream","text":["[1,   200] loss:0.116\n","[1,   400] loss:0.116\n","[1,   600] loss:0.113\n","[2,   200] loss:0.108\n","[2,   400] loss:0.105\n","[2,   600] loss:0.106\n","Finished Training\n"],"name":"stdout"}]}]}